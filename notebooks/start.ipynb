{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1756dbba6c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import os\n",
    "os.chdir('../')\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tkinter import TclError\n",
    "\n",
    "# use this backend to display in separate Tk window\n",
    "%matplotlib tk\n",
    "\n",
    "# constants\n",
    "CHUNK = 1024 * 2             # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 44100                 # samples per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream started\n",
      "stream stopped\n",
      "average frame rate = 21 FPS\n"
     ]
    }
   ],
   "source": [
    "# create matplotlib figure and axes\n",
    "fig, ax = plt.subplots(1, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "\n",
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)\n",
    "\n",
    "# create a line object with random data\n",
    "line, = ax.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# basic formatting for the axes\n",
    "ax.set_title('AUDIO WAVEFORM')\n",
    "ax.set_xlabel('samples')\n",
    "ax.set_ylabel('volume')\n",
    "ax.set_ylim(0, 255)\n",
    "ax.set_xlim(0, 2 * CHUNK)\n",
    "plt.setp(ax, xticks=[0, CHUNK, 2 * CHUNK], yticks=[0, 128, 255])\n",
    "\n",
    "# show the plot\n",
    "plt.show(block=False)\n",
    "\n",
    "print('stream started')\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # binary data\n",
    "    data = stream.read(CHUNK)  \n",
    "    \n",
    "    # convert data to integers, make np array, then offset it by 127\n",
    "    data_int = struct.unpack(str(2 * CHUNK) + 'B', data)\n",
    "    \n",
    "    # create np array and offset by 128\n",
    "    data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "    \n",
    "    line.set_ydata(data_np)\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "        \n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Dataset Preparation\n",
    "\n",
    "Input to model : 8 sec of audio clip with My sound Dubbed in between . \n",
    "\n",
    "Label : Label some number of time steps \n",
    "\n",
    "Inference : Model listens for 8 second for a while. Then, processes it . waits for a while. Then, Processes ..\n",
    "\n",
    "More like, multithread, such that, by time it processes for prediction generation, it's preparing next wave .\n",
    "\n",
    "The computaiton control is done by time.sleep .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython.display.Audio(\"data/external/sample_internet.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "song = AudioSegment.from_wav('./data/external/podact_data/train_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pydub.audio_segment.AudioSegment"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "type(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load training examles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traning Clip Vol :  -30.7636744506485\nTraning Clip Vol :  -36.48736885673499\nTraning Clip Vol :  -37.11067469779735\nTraning Clip Vol :  -39.304431638092474\nTraning Clip Vol :  -33.38225645659825\nTraning Clip Vol :  -39.80810255845745\nTraning Clip Vol :  -43.66022950088225\nTraning Clip Vol :  -42.07660457992975\nTraning Clip Vol :  -43.03675910135147\nTraning Clip Vol :  -39.91243882367998\nTraning Clip Vol :  -32.624423306542276\nTraning Clip Vol :  -37.18703465893772\nTraning Clip Vol :  -36.95993964139527\nTraning Clip Vol :  -32.51176427403059\nTraning Clip Vol :  -36.59416392714908\nTraning Clip Vol :  -41.68172341601461\nTraning Clip Vol :  -41.273269988708556\nTraning Clip Vol :  -41.97618855242873\n"
     ]
    }
   ],
   "source": [
    "root_ =  './data/external/podact_data/activates_robin'\n",
    "clips = []\n",
    "for i in os.listdir(root_):\n",
    "    if i[0].isdigit():\n",
    "        clip_path = os.path.join( root_ , i ) \n",
    "        clip = AudioSegment.from_wav(clip_path)\n",
    "        print('Traning Clip Vol : ' , clip.dBFS )\n",
    "        clips.append( clip )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_song_length = song.duration_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.playback import play\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "play( song[23.9999999 * n : 29 * n] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_activate( clip_list ):\n",
    "    return random.choice(clip_list)\n",
    "\n",
    "## experimental \n",
    "def adjust_level(sound, deviation=None , default = True):\n",
    "    if default or deviation is None:\n",
    "        return sound\n",
    "    else:\n",
    "        difference = np.random.normal(clip.dBFS , deviation )\n",
    "        print(f'Original : {clip.dBFS}')\n",
    "        print(f'Deviated by : {difference}')\n",
    "        return sound.apply_gain(difference)\n",
    "\n",
    "def sample_from_background( background , total_duration_sec , clip_size = 8 ,  multiplier = 1000 ):\n",
    "        \n",
    "    total_duration_ = total_duration_sec - clip_size\n",
    "    selection_start = np.random.uniform(  0 , total_duration_  ) \n",
    "    selection_end = (selection_start + clip_size) * multiplier\n",
    "        \n",
    "    background_clip = background[ selection_start * multiplier : selection_end  ] \n",
    "    return background_clip\n",
    "\n",
    "def overlay_clip_to_bg( background , clip ):\n",
    "    '''\n",
    "        Dub Clip to background\n",
    "    '''\n",
    "    overlay_point_start = np.random.uniform( 0 , background.duration_seconds ) * 1000\n",
    "    overlay_point_end = overlay_point_start + len(clip)\n",
    "    overlay_point_end = min( len(background) , overlay_point_end  )\n",
    "    \n",
    "    return background.overlay( clip , position =  overlay_point_start ) , overlay_point_start , overlay_point_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## check the goddamn speed\n",
    "for i in range(3000):\n",
    "    _ = sample_from_background(song, total_song_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_example( background , voice_clips ):\n",
    "    \n",
    "    total_background_length = background.duration_seconds \n",
    "    background = sample_from_background( background , total_background_length )\n",
    "    \n",
    "    ## positive labels here\n",
    "    if np.random.uniform(0,1) > 0.5:\n",
    "        print('Positive Example Added')\n",
    "        clip_to_dub = sample_from_activate( voice_clips )\n",
    "        overlayed_clip, time_stamp_start , time_stamp_end = overlay_clip_to_bg( background, clip_to_dub )  \n",
    "        return overlayed_clip , time_stamp_start , time_stamp_end\n",
    "    \n",
    "    else:\n",
    "        print('Negative Example Added')\n",
    "        return background , None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positive Example Added\n"
     ]
    }
   ],
   "source": [
    "test_overlay , s ,e = generate_single_example( song , clips )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6753.366553396142, 7542.366553396142)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "s,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "len(test_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(test_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Robin\\\\Downloads\\\\million_dollar_projects\\\\podcast_research\\\\Podcast-Audio-Processing'"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data\\\\external\\\\processed\\\\test.wav'>"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "test_overlay.export('data\\\\external\\\\processed\\\\test.wav',format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_examples( no_of_examples = 1000 ):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('audio': conda)",
   "metadata": {
    "interpreter": {
     "hash": "02d289266c1f598b099c7849ce479cb9f9270efb160b9eb85e1a60405dc1d2ce"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}